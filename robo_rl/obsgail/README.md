
## References
1. [Generative Adversarial Imitation Learning](https://arxiv.org/pdf/1606.03476.pdf)
2. [Learning human behaviour from motion capture by adverserial imitation](https://arxiv.org/pdf/1707.02201.pdf)
3. [Robust Imitation of Diverse Behaviors](https://arxiv.org/pdf/1707.02747.pdf)
4. [Addressing Sample Inefficiency and Reward Bias in Inverse Reinforcement Learning](https://arxiv.org/pdf/1809.02925.pdf)
5. [InfoGAIL: Interpretable Imitation Learning from Visual Demonstrations](https://arxiv.org/pdf/1703.08840.pdf)
6. [Addressing Function Approximation Error in Actor-Critic Methods](https://arxiv.org/pdf/1802.09477.pdf)
7. [Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor](https://arxiv.org/pdf/1801.01290.pdf)
8. [Data Augmentation Generative Adversarial Networks](https://arxiv.org/pdf/1711.04340.pdf)
9. [Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow](https://xbpeng.github.io/projects/VDB/2018_VDB.pdf)
10. [Improved Training of Wasserstein GANs](https://arxiv.org/pdf/1704.00028.pdf)
11. [Skills from Videos](https://xbpeng.github.io/projects/SFV/2018_TOG_SFV.pdf)
12. [Deep Unsupervised Clustering with Gaussian Mixture Variational Autoencoders](https://arxiv.org/pdf/1611.02648.pdf)
